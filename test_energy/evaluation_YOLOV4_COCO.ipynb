{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file should run in python3 envrionment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import time\n",
    "import xml.dom.minidom\n",
    "import pathlib\n",
    "import json\n",
    "import gc\n",
    "import tqdm\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../common\"))\n",
    "\n",
    "import pynq\n",
    "import lpcv_eval\n",
    "\n",
    "team_name = 'LIVES'\n",
    "team = lpcv_eval.Team(team_name, batch_size = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import your processing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utils\n",
    "import utils_yolov4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run all process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "interval_time = 0\n",
    "total_time = 0\n",
    "total_energy = 0\n",
    "\n",
    "team.reset_batch_count()\n",
    "rails = pynq.get_rails()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detector with bit file name and model name\n",
    "# you can replace the default bit file by your own bit\n",
    "detector = utils_yolov4.Processor(bit_name = \"dpu.bit\", model_name = \"dpu1.3_coco55M_v4.xmodel\")\n",
    "\n",
    "RESULT_DIR = pathlib.Path('/home/xilinx/jupyter_notebooks/lpcv_2021/epoch_json')\n",
    "\n",
    "if not os.path.exists(RESULT_DIR):  \n",
    "      os.mkdir(RESULT_DIR) \n",
    "\n",
    "def save_epoch_results_json(save_dir, epoch, result_rectangle):      \n",
    "        json_file = open(save_dir / str(str(epoch) + \"epoch_time\"+ \".json\"), \"w\") \n",
    "        datas = []\n",
    "        for i in range(len(result_rectangle)):  \n",
    "            image_id = int(result_rectangle[i][0])\n",
    "            label = int(result_rectangle[i][5])\n",
    "            x = result_rectangle[i][1]\n",
    "            y = result_rectangle[i][2]\n",
    "            width = result_rectangle[i][3]\n",
    "            height = result_rectangle[i][4]\n",
    "            score = result_rectangle[i][6]\n",
    "            data = {\"image_id\" : image_id, \n",
    "                    \"category_id\" : label, \n",
    "                    \"bbox\": [x, y, width, height],\n",
    "                    \"score\": score,\n",
    "                    }\n",
    "\n",
    "            datas.append(data)\n",
    "\n",
    "        json.dump(datas, json_file)\n",
    "        json_file.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time() \n",
    "# 5V power rail is used as an example for full sytem power modify the code below\n",
    "# refer to ultra96_pmbus.ipynb notebook under \n",
    "# /home/xilinx/jupyter_notebooks/common/ultra96_pmbus.ipynb for details on power rails\n",
    "# recorder = pynq.DataRecorder(rails[\"5V\"].power) \n",
    "recorder = pynq.DataRecorder(rails[\"5V\"].power)\n",
    "\n",
    "\n",
    "epoch_results = list()\n",
    "epoch_images = []\n",
    "\n",
    "max_epoch    = 21000\n",
    "current_epoch = 0\n",
    "total_num = 0\n",
    "\n",
    "with recorder.record(0.05): \n",
    "    while True:\n",
    "        gc.collect()\n",
    "        # get a batch of images\n",
    "        image_paths = team.get_next_batch()\n",
    "        if image_paths is None:\n",
    "            break\n",
    "        \n",
    "        if current_epoch >= max_epoch:\n",
    "            break\n",
    "            \n",
    "        current_epoch = current_epoch + 1\n",
    "        \n",
    "        batch_images = list()\n",
    "        batch_result = []\n",
    "        \n",
    "        epoch_results = list()\n",
    "        epoch_images = []\n",
    "        \n",
    "        \n",
    "        # run processor and save output  \n",
    "        for image_path in image_paths:\n",
    "            print(\"image_path:\", image_path)\n",
    "            bgr_img = cv2.imread(str(image_path))    \n",
    "            batch_images.append(bgr_img)\n",
    "            epoch_images.append([image_path,bgr_img])\n",
    "              \n",
    "        batch_result = detector.run(batch_images)\n",
    "       \n",
    "        #print(\"batch result \", batch_result)\n",
    "        # print(\"batch result size:\", len(batch_result))\n",
    "        \n",
    "        for i in range(len(batch_result)):\n",
    "            epoch_results.append(batch_result[i])\n",
    "            \n",
    "        cur_num = len(batch_result)\n",
    "        total_num = total_num + cur_num\n",
    "        \n",
    "                \n",
    "        batch_result = None\n",
    "        image_paths  =  None\n",
    "        del batch_result\n",
    "        del image_paths\n",
    "        \n",
    "        gc.collect()\n",
    "        # Format  batch results and save\n",
    "        save_epoch_results = []\n",
    "        for i in range(len(epoch_results)):\n",
    "            for j in range(len(epoch_results[i])):\n",
    "                label = epoch_results[i][j][4]\n",
    "                score = epoch_results[i][j][5]\n",
    "                x = epoch_results[i][j][0] * epoch_images[i][1].shape[1] + 1\n",
    "                y = epoch_results[i][j][1] * epoch_images[i][1].shape[0] + 1\n",
    "                width = epoch_results[i][j][2] * epoch_images[i][1].shape[1]\n",
    "                height = epoch_results[i][j][3] * epoch_images[i][1].shape[0]\n",
    "               \n",
    "                image_id = str(epoch_images[i][0]).split('/')[-1].split('.')[0]\n",
    "                save_epoch_results.append([image_id, x, y, width, height, label, score])\n",
    "    \n",
    "        # team.save_results_xml(save_results, total_time, total_energy)\n",
    "        # save results to json file for test accuracy\n",
    "        save_epoch_results_json(RESULT_DIR,current_epoch, save_epoch_results)\n",
    "        print(\"save current epoch result, and this is the  epoch :\", current_epoch)\n",
    "        \n",
    "        batch_images = None  \n",
    "        \n",
    "        epoch_results = None\n",
    "        epoch_images  = None \n",
    "        save_epoch_results = None \n",
    "        \n",
    "        \n",
    "        del   batch_images \n",
    "        \n",
    "        del   epoch_results \n",
    "        del   epoch_images \n",
    "        del   save_epoch_results\n",
    "        gc.collect()\n",
    " \n",
    "                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #timer stop after batch processing is complete\n",
    "end = time.time()\n",
    "t = end - start\n",
    "total_time = t\n",
    "\n",
    "#print('All processing time: {} seconds.'.format(total_time))\n",
    "print(\"The whole number of  images:\", total_num )\n",
    "\n",
    "# Energy measurements    \n",
    "# energy = recorder.frame[\"5V_power\"].mean() * t    \n",
    "energy = recorder.frame[\"5V_power\"].mean() * t \n",
    "\n",
    "total_energy = energy\n",
    "print(\"Total time:\", total_time, \"seconds\")\n",
    "print(\"Total energy:\", total_energy, \"J\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_json(path_results, path_merges):\n",
    "    \"\"\"\n",
    "    :param path_results:\n",
    "    :param path_merges:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    merges_file = os.path.join(path_merges, \"LIVES.json\")\n",
    "    with open(merges_file, \"w\", encoding=\"utf-8\") as f0:\n",
    "        for file in os.listdir(path_results):\n",
    "            with open(os.path.join(path_results, file), \"r\", encoding=\"utf-8\") as f1:\n",
    "                for line in tqdm.tqdm(f1):\n",
    "                    line_dict = json.loads(line)\n",
    "                    js = json.dumps(line_dict, ensure_ascii=False)\n",
    "                    f0.write(js + '\\n')\n",
    "                f1.close()\n",
    "        f0.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_results, path_merges = \"./epoch_json\", \"./\"\n",
    "if not os.path.exists(path_merges):  \n",
    "        os.mkdir(path_merges)\n",
    "merge_json(path_results, path_merges)\n",
    "print(\" merge  all results done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
